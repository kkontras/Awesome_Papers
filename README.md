# Awesome_Papers


## Self-Supervised Papers <br />
###Basic <br />
Sim-CLR: [A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/abs/2002.05709)<br />
SupCon: [Supervised Contrastive Learning](https://arxiv.org/abs/2004.11362)<br />
MoCo: [Momentum Contrast for Unsupervised Visual Representation Learning](https://arxiv.org/pdf/1911.05722) and [v2](https://arxiv.org/abs/2003.04297v1)<br />
BYOL: [Bootstrap your own latent](https://arxiv.org/abs/2006.07733)<br />
InfoNCE: [Representation Learning with Contrastive Predictive Coding](https://arxiv.org/abs/1807.03748v2)<br />


## Multimodal Fusion Architectures
###Basic <br />
Multimodal Transformer: [Multimodal Transformer for Unaligned Multimodal Language Sequences](https://pmc.ncbi.nlm.nih.gov/articles/PMC7195022/) <br />
BLIP: [Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation](https://proceedings.mlr.press/v162/li22n.html) and [v2](https://arxiv.org/abs/2301.12597) <br />
MBT: [Attention Bottlenecks for Multimodal Fusion](https://proceedings.neurips.cc/paper_files/paper/2021/file/76ba9f564ebbc35b1014ac498fafadd0-Paper.pdf) <br />

## Multimodal Training Methods
###Basic <br />

###Advanced <br />
AGM<br />
PMR<br />
OGM<br />
MLB<br />
MCR<br />



