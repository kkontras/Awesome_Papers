# Awesome Papers Biomed KU Leuven


## Self-Supervised Learning <br />
### Basic <br />
Sim-CLR: [A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/abs/2002.05709)<br />
SupCon: [Supervised Contrastive Learning](https://arxiv.org/abs/2004.11362)<br />
MoCo: [Momentum Contrast for Unsupervised Visual Representation Learning](https://arxiv.org/pdf/1911.05722) and [v2](https://arxiv.org/abs/2003.04297v1)<br />
BYOL: [Bootstrap your own latent](https://arxiv.org/abs/2006.07733)<br />
InfoNCE: [Representation Learning with Contrastive Predictive Coding](https://arxiv.org/abs/1807.03748v2)<br />

# Generative AI <br />

## Gen AI - Generative Adversarial Networks <br />
WGAN: [Wasserstein GAN](https://doi.org/10.48550/arXiv.1701.07875)<br />
WGAN-GP: [Improved Training of Wasserstein GANs](https://doi.org/10.48550/arXiv.1704.00028)<br />
ProGAN: [Progressive Growing of GANs for Improved Quality, Stability, and Variation](https://doi.org/10.48550/arXiv.1710.10196)<br />
StyleGAN: [A Style-Based Generator Architecture for Generative Adversarial Networks](https://doi.org/10.48550/arXiv.1812.04948)<br />
BigGAN: [Large Scale GAN Training for High Fidelity Natural Image Synthesis](https://doi.org/10.48550/arXiv.1809.11096)<br />
 
## Gen AI - Diffusion Models <br />
DM: [Denoising Diffusion Probabilistic Models](https://doi.org/10.48550/arXiv.2006.11239)<br />
LDM: [High-Resolution Image Synthesis with Latent Diffusion Models](https://doi.org/10.48550/arXiv.2112.10752)<br />

# Graph Neural Networks <br />

GNNsurvey: [A Comprehensive Survey on Graph Neural Networks](https://doi.org/10.1109/TNNLS.2020.2978386)<br/>
Node2vec: [Node2vec: Scalable feature learning for networks](https://doi.org/10.1145/2939672.2939754)<br/>
GCN: [Semi-Supervised Classification with Graph Convolutional Networks](https://doi.org/10.48550/arXiv.1609.02907)<br/>
GAT: [Graph Attention Networks](https://doi.org/10.48550/arXiv.1710.10903)<br/>
 
# Multimodal AI

## Multimodal Fusion Architectures
### Basic <br />
Multimodal Transformer: [Multimodal Transformer for Unaligned Multimodal Language Sequences](https://pmc.ncbi.nlm.nih.gov/articles/PMC7195022/) <br />
BLIP: [Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation](https://proceedings.mlr.press/v162/li22n.html) and [v2](https://arxiv.org/abs/2301.12597) <br />
MBT: [Attention Bottlenecks for Multimodal Fusion](https://proceedings.neurips.cc/paper_files/paper/2021/file/76ba9f564ebbc35b1014ac498fafadd0-Paper.pdf) <br />

## Multimodal Training Methods
### Basic <br />

### Advanced <br />
AGM: [Boosting Multi-modal Model Performance with Adaptive Gradient Modulation](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Boosting_Multi-modal_Model_Performance_with_Adaptive_Gradient_Modulation_ICCV_2023_paper.html)<br />
PMR: [Prototypical Modal Rebalance for Multimodal Learning](https://openaccess.thecvf.com/content/CVPR2023/papers/Fan_PMR_Prototypical_Modal_Rebalance_for_Multimodal_Learning_CVPR_2023_paper.pdf)<br />
OGM: [Balanced Multimodal Learning via On-the-fly Gradient Modulation](https://arxiv.org/abs/2203.15332) <br />
MLB: [Improving Multimodal Learning with Multi-Loss Gradient Modulation](https://bmva-archive.org.uk/bmvc/2024/papers/Paper_977/paper.pdf)<br />
MCR: [Multimodal Fusion Balancing Through Game-Theoretic Regularization](https://arxiv.org/abs/2411.07335)<br />



# AI on Biomedical<br />

## Digital Twins and Modeling
Cardiac DTs: [The ‘Digital Twin’ to enable the vision of precision cardiology](https://doi.org/10.1093/eurheartj/ehaa159)<br />
Virtual cohorts: [Creation and application of virtual patient cohorts of heart models](https://doi.org/10.1098/rsta.2019.0558)<br />
Cardiac DTs of electrophysiology: [A Framework for the generation of digital twins of cardiac electrophysiology from clinical 12-leads ECGs](https://doi.org/10.1016/j.media.2021.102080)<br />

## Sleep Staging
XSleepnet: []()<br />
SleepTransformer: []()<br />
CoRe-Sleep: []()<br />
L-SeqSleepNet: []()<br />


